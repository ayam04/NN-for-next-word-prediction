{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dense, Activation\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = pd.read_csv(\"dataset/fake_or_real_news.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = list(text_df['text'].values)\n",
    "joined_text = \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_text = joined_text[:1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "tokens = tokenizer.tokenize(partial_text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tokens = np.unique(tokens)\n",
    "unique_tokens_indexed = {token: idx for idx, token in enumerate(unique_tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_words = 10\n",
    "input_words = []\n",
    "next_words = []\n",
    "\n",
    "for i in range(len(tokens)-n_words):\n",
    "    input_words.append(tokens[i:i + n_words])\n",
    "    next_words.append(tokens[i + n_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((len(input_words), n_words, len(unique_tokens)), dtype=bool)\n",
    "y = np.zeros((len(next_words), len(unique_tokens)),dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for  i, words in enumerate(input_words):\n",
    "    for j, word in enumerate(words):\n",
    "        x[i, j, unique_tokens_indexed[word]] = 1\n",
    "    y[i, unique_tokens_indexed[next_words[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(n_words, len(unique_tokens)), return_sequences=True))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(len(unique_tokens)))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1318/1318 [==============================] - 649s 486ms/step - loss: 7.2300 - accuracy: 0.0608\n",
      "Epoch 2/50\n",
      "1318/1318 [==============================] - 649s 493ms/step - loss: 7.3832 - accuracy: 0.0863\n",
      "Epoch 3/50\n",
      "1318/1318 [==============================] - 659s 500ms/step - loss: 7.6546 - accuracy: 0.0968\n",
      "Epoch 4/50\n",
      "1318/1318 [==============================] - 653s 495ms/step - loss: 7.6136 - accuracy: 0.1054\n",
      "Epoch 5/50\n",
      "1318/1318 [==============================] - 7730s 6s/step - loss: 7.5373 - accuracy: 0.1105\n",
      "Epoch 6/50\n",
      "1318/1318 [==============================] - 645s 489ms/step - loss: 7.4420 - accuracy: 0.1153\n",
      "Epoch 7/50\n",
      "1318/1318 [==============================] - 642s 487ms/step - loss: 7.2880 - accuracy: 0.1236\n",
      "Epoch 8/50\n",
      "1318/1318 [==============================] - 636s 482ms/step - loss: 7.1100 - accuracy: 0.1336\n",
      "Epoch 9/50\n",
      "1318/1318 [==============================] - 718s 545ms/step - loss: 6.8342 - accuracy: 0.1483\n",
      "Epoch 10/50\n",
      "1318/1318 [==============================] - 721s 547ms/step - loss: 6.6095 - accuracy: 0.1641\n",
      "Epoch 11/50\n",
      "1318/1318 [==============================] - 638s 484ms/step - loss: 6.3677 - accuracy: 0.1820\n",
      "Epoch 12/50\n",
      "1318/1318 [==============================] - 629s 477ms/step - loss: 6.1462 - accuracy: 0.1992\n",
      "Epoch 13/50\n",
      "1318/1318 [==============================] - 628s 476ms/step - loss: 5.9386 - accuracy: 0.2176\n",
      "Epoch 14/50\n",
      "1318/1318 [==============================] - 631s 479ms/step - loss: 5.7169 - accuracy: 0.2379\n",
      "Epoch 15/50\n",
      "1318/1318 [==============================] - 627s 476ms/step - loss: 5.5205 - accuracy: 0.2594\n",
      "Epoch 16/50\n",
      "1318/1318 [==============================] - 630s 478ms/step - loss: 5.3185 - accuracy: 0.2792\n",
      "Epoch 17/50\n",
      "1318/1318 [==============================] - 630s 478ms/step - loss: 5.1386 - accuracy: 0.3018\n",
      "Epoch 18/50\n",
      "1318/1318 [==============================] - 627s 476ms/step - loss: 4.9836 - accuracy: 0.3187\n",
      "Epoch 19/50\n",
      "1318/1318 [==============================] - 631s 479ms/step - loss: 4.8386 - accuracy: 0.3381\n",
      "Epoch 20/50\n",
      "1318/1318 [==============================] - 628s 477ms/step - loss: 4.7311 - accuracy: 0.3532\n",
      "Epoch 21/50\n",
      "1318/1318 [==============================] - 628s 477ms/step - loss: 4.6027 - accuracy: 0.3705\n",
      "Epoch 22/50\n",
      "1318/1318 [==============================] - 634s 481ms/step - loss: 4.5210 - accuracy: 0.3826\n",
      "Epoch 23/50\n",
      "1318/1318 [==============================] - 629s 477ms/step - loss: 4.4105 - accuracy: 0.3976\n",
      "Epoch 24/50\n",
      "1318/1318 [==============================] - 681s 517ms/step - loss: 4.3232 - accuracy: 0.4109\n",
      "Epoch 25/50\n",
      "1318/1318 [==============================] - 631s 479ms/step - loss: 4.2953 - accuracy: 0.4192\n",
      "Epoch 26/50\n",
      "1318/1318 [==============================] - 633s 480ms/step - loss: 4.2002 - accuracy: 0.4315\n",
      "Epoch 27/50\n",
      "1318/1318 [==============================] - 637s 483ms/step - loss: 4.1263 - accuracy: 0.4424\n",
      "Epoch 28/50\n",
      "1318/1318 [==============================] - 636s 482ms/step - loss: 4.0761 - accuracy: 0.4520\n",
      "Epoch 29/50\n",
      "1318/1318 [==============================] - 638s 484ms/step - loss: 4.0390 - accuracy: 0.4593\n",
      "Epoch 30/50\n",
      "1318/1318 [==============================] - 635s 482ms/step - loss: 4.0200 - accuracy: 0.4620\n",
      "Epoch 31/50\n",
      "1318/1318 [==============================] - 630s 478ms/step - loss: 3.9926 - accuracy: 0.4688\n",
      "Epoch 32/50\n",
      "1318/1318 [==============================] - 632s 480ms/step - loss: 3.9376 - accuracy: 0.4779\n",
      "Epoch 33/50\n",
      "1318/1318 [==============================] - 629s 477ms/step - loss: 3.9379 - accuracy: 0.4820\n",
      "Epoch 34/50\n",
      "1318/1318 [==============================] - 631s 478ms/step - loss: 3.9002 - accuracy: 0.4866\n",
      "Epoch 35/50\n",
      "1318/1318 [==============================] - 634s 481ms/step - loss: 3.8506 - accuracy: 0.4956\n",
      "Epoch 36/50\n",
      "1318/1318 [==============================] - 628s 476ms/step - loss: 3.8315 - accuracy: 0.4995\n",
      "Epoch 37/50\n",
      "1318/1318 [==============================] - 629s 477ms/step - loss: 3.8147 - accuracy: 0.5045\n",
      "Epoch 38/50\n",
      "1318/1318 [==============================] - 633s 480ms/step - loss: 3.8063 - accuracy: 0.5055\n",
      "Epoch 39/50\n",
      "1318/1318 [==============================] - 632s 480ms/step - loss: 3.7778 - accuracy: 0.5124\n",
      "Epoch 40/50\n",
      "1318/1318 [==============================] - 632s 480ms/step - loss: 3.7962 - accuracy: 0.5117\n",
      "Epoch 41/50\n",
      "1318/1318 [==============================] - 631s 479ms/step - loss: 3.7684 - accuracy: 0.5170\n",
      "Epoch 42/50\n",
      "1318/1318 [==============================] - 631s 479ms/step - loss: 3.7492 - accuracy: 0.5210\n",
      "Epoch 43/50\n",
      "1318/1318 [==============================] - 630s 478ms/step - loss: 3.7543 - accuracy: 0.5218\n",
      "Epoch 44/50\n",
      "1318/1318 [==============================] - 634s 481ms/step - loss: 3.7222 - accuracy: 0.5276\n",
      "Epoch 45/50\n",
      "1318/1318 [==============================] - 632s 479ms/step - loss: 3.7140 - accuracy: 0.5298\n",
      "Epoch 46/50\n",
      "1318/1318 [==============================] - 632s 480ms/step - loss: 3.7236 - accuracy: 0.5303\n",
      "Epoch 47/50\n",
      "1318/1318 [==============================] - 632s 480ms/step - loss: 3.7285 - accuracy: 0.5281\n",
      "Epoch 48/50\n",
      "1318/1318 [==============================] - 630s 478ms/step - loss: 3.6690 - accuracy: 0.5380\n",
      "Epoch 49/50\n",
      "1318/1318 [==============================] - 627s 476ms/step - loss: 3.6920 - accuracy: 0.5342\n",
      "Epoch 50/50\n",
      "1318/1318 [==============================] - 633s 480ms/step - loss: 3.6598 - accuracy: 0.5404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cc000bf610>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=RMSprop(learning_rate=0.01), metrics=[\"accuracy\"])\n",
    "model.fit(x,y, batch_size=128, epochs=50, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"better_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"better_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(input_text, n_best):\n",
    "    input_text = input_text.lower()\n",
    "    x = np.zeros((1, n_words, len(unique_tokens)))\n",
    "    for i, word in enumerate(input_text.split()):\n",
    "        x[0, i, unique_tokens_indexed[word]] = 1\n",
    "    \n",
    "    predictions = model.predict(x)[0]\n",
    "    return np.argpartition(predictions, -n_best)[-n_best:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 904ms/step\n"
     ]
    }
   ],
   "source": [
    "possible = predict_next_word(\"he is the\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['so', 'and', 'those', 'two', 'hate']\n"
     ]
    }
   ],
   "source": [
    "print([unique_tokens[idx] for idx in possible])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(input_text, text_lenght, creativity= 3):\n",
    "    word_sequence = input_text.split()\n",
    "    current = 0\n",
    "    for _ in range(text_lenght):\n",
    "        sub_sequence = \" \".join(tokenizer.tokenize(\" \".join(word_sequence).lower())[current:current+n_words])\n",
    "        try:\n",
    "            choice = unique_tokens[random.choice(predict_next_word(sub_sequence,creativity))]\n",
    "        except:\n",
    "            choice = random.choice(unique_tokens)\n",
    "        word_sequence.append(choice)\n",
    "        current+=1\n",
    "    return \" \".join(word_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'he is the hate hate those hate june two 14 two the in 14 the in wait so hate 14 and so in 17 two and those so your 14 those your again those those two and again those 14 a 14 and and those your hate 14 so your should your 14 and again and hate your wait or those so those two so hate your 14 and 14 should 14 should those the those two those hate so hate your hate those again hate those or two two those and and your those so again those those new and democratic those'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"he is the\",100,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
